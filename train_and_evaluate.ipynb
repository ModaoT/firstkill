{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用于测试集的划分\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 进度条工具\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 32)\n(1, 32)\n(3,)\n(1,)\n"
     ]
    }
   ],
   "source": [
    "train_feature = train_merged_2.drop('label', axis=1)\n",
    "train_label = train_merged_2['label']\n",
    "\n",
    "# 为了防止过拟合，需要从训练集中划分出一个验证集来\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_feature, train_label, test_size=0.1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# 此数据集的测试集中没有label，仅用于提交结果，所以需要在训练完毕后对此集做推理运算，得出label\n",
    "test_feature = test_merged_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 通过得到的特征向量与标签，用tensorflow搭建神经网络进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设计神经网络结构\n",
    "def build_arch(inputs):\n",
    "    layer1 = tf.layers.dense(inputs, 128, activation=tf.nn.relu)\n",
    "    layer2 = tf.layers.dense(layer1, 128, activation=tf.nn.relu)\n",
    "    layer3 = tf.layers.dense(layer2, 128, activation=tf.nn.relu)\n",
    "    outputs = tf.layers.dense(layer3, 1, activation=tf.nn.relu)\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设计损失函数\n",
    "def build_loss(outputs, labels):\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(outputs, labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# approximated AUC loss function\n",
    "def build_AUC_loss(outputs, labels):\n",
    "    \n",
    "    posi_idx = tf.where(tf.equal(labels,1.0))\n",
    "    neg_idx = tf.where(tf.equal(labels,-1.0))\n",
    "    \n",
    "    prdictions = tf.nn.softmax(outputs)\n",
    "    # 注意以下数据的纬度\n",
    "    posi_predict = tf.gather(prdictions, posi_idx)\n",
    "    posi_size = tf.shape(posi_predict)[0]\n",
    "    \n",
    "    neg_predict = tf.gather(prdictions, neg_idx)\n",
    "    neg_size = tf.shape(posi_predict)[0]\n",
    "    \n",
    "    gamma = 0.1\n",
    "    power_p = 2\n",
    "    posi_neg_diff = tf.reshape(\n",
    "                        -(tf.matmul(posi_predict,tf.ones([1,neg_size])) -\n",
    "                        tf.matmul(tf.ones([posi_size,1]), tf.reshape(neg_predict,[-1,neg_size]) ) - gamma),\n",
    "                        [-1,1]\n",
    "                               )\n",
    "    posi_neg_diff = tf.where(tf.greater(posi_neg_diff,0),posi_neg_diff,tf.zeros([posi_size*neg_size,1]))\n",
    "    posi_neg_diff = tf.pow(posi_neg_diff,power_p)\n",
    "    \n",
    "    loss_approx_auc = tf.reduce_mean(posi_neg_diff)\n",
    "    return loss_approx_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设计分数统计函数\n",
    "def build_score(outputs, labels):\n",
    "    score = 0\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取上一次保存的模型\n",
    "def get_last_state(logdir, num_batch):\n",
    "    ckpt = tf.train.get_checkpoint_state(logdir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        # Restores from checkpoint\n",
    "        ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "        global_step = int(ckpt_name.split('-')[-1])\n",
    "        last_epoch = global_step // num_batch\n",
    "        last_step = global_step % num_batch\n",
    "    else:\n",
    "        global_step = 0\n",
    "        last_epoch = 0\n",
    "        last_step = 0\n",
    "    return ckpt, global_step, last_epoch, last_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建计算图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调试超参\n",
    "lr = 0.1\n",
    "batch_size = 128\n",
    "epoch = 1\n",
    "logdir = 'log/'\n",
    "save_checkpoint_steps = 20\n",
    "save_summaries_steps = 10\n",
    "#AUC parameter\n",
    "gammar = 0.1\n",
    "power_p = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "outputs = build_arch(X_train)\n",
    "loss = build_loss(outputs, y_train)\n",
    "score = build_score(outputs, y_train)\n",
    "opt = tf.train.AdamOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batch = X_train.shape[0] // batch_size\n",
    "ckpt, global_step, last_epoch, last_step = get_last_state(logdir, num_batch)\n",
    "init_op = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    train_writer = tf.summary.FileWriter(logdir + '/train', sess.graph)\n",
    "    \n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        # 加载上次保存的模型\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    # 计算图结构分析\n",
    "    param_stats = tf.contrib.tfprof.model_analyzer.print_model_analysis(\n",
    "            tf.get_default_graph(),\n",
    "            tfprof_options=tf.contrib.tfprof.model_analyzer.TRAINABLE_VARS_PARAMS_STAT_OPTIONS)\n",
    "    print('total_params: %d\\n' % param_stats.total_parameters)\n",
    "    \n",
    "    for e in range(last_epoch, epoch):\n",
    "        print('Training for epoch ' + str(epoch+1) + '/' + str(epoch) + ':')\n",
    "        \n",
    "        bar = tqdm(range(last_step, num_batch), initial=last_step, total=num_batch, ncols=100, leave=False,\n",
    "                       unit='b')\n",
    "        for _ in bar:\n",
    "            if global_step % save_summaries_steps == 0:\n",
    "                # train\n",
    "                _, train_score, summary_str = sess.run(\n",
    "                        [opt, score, summary])\n",
    "                train_writer.add_summary(summary_str, global_step)\n",
    "                bar.set_description('tr_acc:{}'.format(train_score))\n",
    "            else:\n",
    "                sess.run(opt)\n",
    "\n",
    "            global_step += 1\n",
    "            if global_step % save_checkpoint_steps == 0:\n",
    "                saver.save(sess, logdir + '/model.ckpt', global_step=global_step)\n",
    "\n",
    "    train_writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}